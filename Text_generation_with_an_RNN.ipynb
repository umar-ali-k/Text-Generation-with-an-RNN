{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text generation with an RNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umar-ali-k/Text-Generation-with-an-RNN/blob/master/Text_generation_with_an_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ6ywSZtKnjN",
        "colab_type": "text"
      },
      "source": [
        "## Install tensorflow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9FKug05KO7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFmx7xDLJr9h",
        "colab_type": "text"
      },
      "source": [
        "## Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCkynm3yKc9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkbXEaLuLIkV",
        "colab_type": "text"
      },
      "source": [
        "## Set the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UATV3LPFK841",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5a00063e-cf34-43ce-c980-30a6c9586810"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data=\"\"\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n \n",
        "Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\n\n",
        "Who didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\n\n",
        "Of the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\n\n",
        "For all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\n\n",
        "Were dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\n\n",
        "She tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\n\n",
        "Just in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\n\n",
        "Potatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\n\n",
        "Courting the girls and dancing away. \\nSongs they went round as plenty as water, \\n\n",
        "The harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\n\n",
        "All singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\n\n",
        "All round the room in a whirligig. \\nJulia and I, we banished their nonsense \\n\n",
        "And tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\n\n",
        "Danced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\n\n",
        "Learning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\n\n",
        "Three long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\n\n",
        "Learning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\n\n",
        "I stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\n\n",
        "Learning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\\n",
        " danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\n\n",
        " Put his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\n\n",
        " Called for her brothers and gathered them all. \\nCarmody swore that hed go no further \\n\n",
        " Til he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\n\n",
        " Her cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\n\n",
        " \n",
        " She took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\n\n",
        " When he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\n\n",
        " And smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\n\n",
        " Myself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\n\n",
        " Old Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\n\n",
        " The girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\"\"\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
            "263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ1YAEzpLtyo",
        "colab_type": "text"
      },
      "source": [
        "## Pad the Sequences. Create predictors and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ep9lE0uL-TZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvAs-ciHMMEQ",
        "colab_type": "text"
      },
      "source": [
        "## Map the words with the integer tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAzQSdVPMDuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "933ab73b-9190-464a-964e-f2135cdce20f"
      },
      "source": [
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "66\n",
            "8\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVcJMOLgMaxJ",
        "colab_type": "text"
      },
      "source": [
        "# Sequential Model having Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvkx3RUkMSGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c0da3f2-b1bc-4cea-8390-391cf35903e0"
      },
      "source": [
        "  model = Sequential()\n",
        "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "  model.add(Bidirectional(LSTM(20)))\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(xs, ys, epochs=500, verbose=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 453 samples\n",
            "Epoch 1/500\n",
            "453/453 [==============================] - 1s 3ms/sample - loss: 5.5697 - accuracy: 0.0088\n",
            "Epoch 2/500\n",
            "453/453 [==============================] - 0s 627us/sample - loss: 5.5495 - accuracy: 0.0618\n",
            "Epoch 3/500\n",
            "453/453 [==============================] - 0s 630us/sample - loss: 5.5059 - accuracy: 0.0486\n",
            "Epoch 4/500\n",
            "453/453 [==============================] - 0s 625us/sample - loss: 5.3599 - accuracy: 0.0486\n",
            "Epoch 5/500\n",
            "453/453 [==============================] - 0s 654us/sample - loss: 5.1613 - accuracy: 0.0486\n",
            "Epoch 6/500\n",
            "453/453 [==============================] - 0s 674us/sample - loss: 5.0811 - accuracy: 0.0486\n",
            "Epoch 7/500\n",
            "453/453 [==============================] - 0s 651us/sample - loss: 5.0474 - accuracy: 0.0442\n",
            "Epoch 8/500\n",
            "453/453 [==============================] - 0s 605us/sample - loss: 5.0215 - accuracy: 0.0662\n",
            "Epoch 9/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 4.9963 - accuracy: 0.0662\n",
            "Epoch 10/500\n",
            "453/453 [==============================] - 0s 642us/sample - loss: 4.9672 - accuracy: 0.0662\n",
            "Epoch 11/500\n",
            "453/453 [==============================] - 0s 646us/sample - loss: 4.9415 - accuracy: 0.0640\n",
            "Epoch 12/500\n",
            "453/453 [==============================] - 0s 621us/sample - loss: 4.9126 - accuracy: 0.0640\n",
            "Epoch 13/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 4.8817 - accuracy: 0.0596\n",
            "Epoch 14/500\n",
            "453/453 [==============================] - 0s 614us/sample - loss: 4.8549 - accuracy: 0.0640\n",
            "Epoch 15/500\n",
            "453/453 [==============================] - 0s 616us/sample - loss: 4.8237 - accuracy: 0.0640\n",
            "Epoch 16/500\n",
            "453/453 [==============================] - 0s 621us/sample - loss: 4.7990 - accuracy: 0.0640\n",
            "Epoch 17/500\n",
            "453/453 [==============================] - 0s 632us/sample - loss: 4.7607 - accuracy: 0.0618\n",
            "Epoch 18/500\n",
            "453/453 [==============================] - 0s 632us/sample - loss: 4.7271 - accuracy: 0.0684\n",
            "Epoch 19/500\n",
            "453/453 [==============================] - 0s 649us/sample - loss: 4.6942 - accuracy: 0.0706\n",
            "Epoch 20/500\n",
            "453/453 [==============================] - 0s 670us/sample - loss: 4.6585 - accuracy: 0.0728\n",
            "Epoch 21/500\n",
            "453/453 [==============================] - 0s 609us/sample - loss: 4.6240 - accuracy: 0.0883\n",
            "Epoch 22/500\n",
            "453/453 [==============================] - 0s 637us/sample - loss: 4.5792 - accuracy: 0.0971\n",
            "Epoch 23/500\n",
            "453/453 [==============================] - 0s 608us/sample - loss: 4.5194 - accuracy: 0.1060\n",
            "Epoch 24/500\n",
            "453/453 [==============================] - 0s 684us/sample - loss: 4.4543 - accuracy: 0.1126\n",
            "Epoch 25/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 4.3727 - accuracy: 0.1192\n",
            "Epoch 26/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 4.2961 - accuracy: 0.1325\n",
            "Epoch 27/500\n",
            "453/453 [==============================] - 0s 617us/sample - loss: 4.2204 - accuracy: 0.1347\n",
            "Epoch 28/500\n",
            "453/453 [==============================] - 0s 664us/sample - loss: 4.1667 - accuracy: 0.1391\n",
            "Epoch 29/500\n",
            "453/453 [==============================] - 0s 601us/sample - loss: 4.1117 - accuracy: 0.1523\n",
            "Epoch 30/500\n",
            "453/453 [==============================] - 0s 647us/sample - loss: 4.0551 - accuracy: 0.1457\n",
            "Epoch 31/500\n",
            "453/453 [==============================] - 0s 659us/sample - loss: 4.0105 - accuracy: 0.1722\n",
            "Epoch 32/500\n",
            "453/453 [==============================] - 0s 649us/sample - loss: 3.9585 - accuracy: 0.1876\n",
            "Epoch 33/500\n",
            "453/453 [==============================] - 0s 604us/sample - loss: 3.9138 - accuracy: 0.1965\n",
            "Epoch 34/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 3.8729 - accuracy: 0.2053\n",
            "Epoch 35/500\n",
            "453/453 [==============================] - 0s 607us/sample - loss: 3.8202 - accuracy: 0.2185\n",
            "Epoch 36/500\n",
            "453/453 [==============================] - 0s 644us/sample - loss: 3.7739 - accuracy: 0.2406\n",
            "Epoch 37/500\n",
            "453/453 [==============================] - 0s 630us/sample - loss: 3.7395 - accuracy: 0.2494\n",
            "Epoch 38/500\n",
            "453/453 [==============================] - 0s 698us/sample - loss: 3.6833 - accuracy: 0.2517\n",
            "Epoch 39/500\n",
            "453/453 [==============================] - 0s 630us/sample - loss: 3.6412 - accuracy: 0.2583\n",
            "Epoch 40/500\n",
            "453/453 [==============================] - 0s 637us/sample - loss: 3.5926 - accuracy: 0.2804\n",
            "Epoch 41/500\n",
            "453/453 [==============================] - 0s 624us/sample - loss: 3.5458 - accuracy: 0.2715\n",
            "Epoch 42/500\n",
            "453/453 [==============================] - 0s 624us/sample - loss: 3.5099 - accuracy: 0.2804\n",
            "Epoch 43/500\n",
            "453/453 [==============================] - 0s 629us/sample - loss: 3.4714 - accuracy: 0.2936\n",
            "Epoch 44/500\n",
            "453/453 [==============================] - 0s 660us/sample - loss: 3.4269 - accuracy: 0.3024\n",
            "Epoch 45/500\n",
            "453/453 [==============================] - 0s 648us/sample - loss: 3.3938 - accuracy: 0.3179\n",
            "Epoch 46/500\n",
            "453/453 [==============================] - 0s 647us/sample - loss: 3.3468 - accuracy: 0.3157\n",
            "Epoch 47/500\n",
            "453/453 [==============================] - 0s 632us/sample - loss: 3.3059 - accuracy: 0.3289\n",
            "Epoch 48/500\n",
            "453/453 [==============================] - 0s 660us/sample - loss: 3.2691 - accuracy: 0.3311\n",
            "Epoch 49/500\n",
            "453/453 [==============================] - 0s 647us/sample - loss: 3.2305 - accuracy: 0.3488\n",
            "Epoch 50/500\n",
            "453/453 [==============================] - 0s 595us/sample - loss: 3.2084 - accuracy: 0.3510\n",
            "Epoch 51/500\n",
            "453/453 [==============================] - 0s 644us/sample - loss: 3.1965 - accuracy: 0.3466\n",
            "Epoch 52/500\n",
            "453/453 [==============================] - 0s 651us/sample - loss: 3.1473 - accuracy: 0.3598\n",
            "Epoch 53/500\n",
            "453/453 [==============================] - 0s 648us/sample - loss: 3.1235 - accuracy: 0.3620\n",
            "Epoch 54/500\n",
            "453/453 [==============================] - 0s 625us/sample - loss: 3.0856 - accuracy: 0.3819\n",
            "Epoch 55/500\n",
            "453/453 [==============================] - 0s 692us/sample - loss: 3.0308 - accuracy: 0.3709\n",
            "Epoch 56/500\n",
            "453/453 [==============================] - 0s 632us/sample - loss: 2.9966 - accuracy: 0.3974\n",
            "Epoch 57/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 2.9505 - accuracy: 0.4150\n",
            "Epoch 58/500\n",
            "453/453 [==============================] - 0s 682us/sample - loss: 2.9187 - accuracy: 0.4062\n",
            "Epoch 59/500\n",
            "453/453 [==============================] - 0s 657us/sample - loss: 2.8929 - accuracy: 0.4415\n",
            "Epoch 60/500\n",
            "453/453 [==============================] - 0s 659us/sample - loss: 2.8490 - accuracy: 0.4305\n",
            "Epoch 61/500\n",
            "453/453 [==============================] - 0s 595us/sample - loss: 2.8153 - accuracy: 0.4437\n",
            "Epoch 62/500\n",
            "453/453 [==============================] - 0s 645us/sample - loss: 2.8259 - accuracy: 0.4393\n",
            "Epoch 63/500\n",
            "453/453 [==============================] - 0s 624us/sample - loss: 2.7579 - accuracy: 0.4525\n",
            "Epoch 64/500\n",
            "453/453 [==============================] - 0s 658us/sample - loss: 2.7274 - accuracy: 0.4614\n",
            "Epoch 65/500\n",
            "453/453 [==============================] - 0s 626us/sample - loss: 2.7015 - accuracy: 0.4592\n",
            "Epoch 66/500\n",
            "453/453 [==============================] - 0s 697us/sample - loss: 2.6604 - accuracy: 0.4812\n",
            "Epoch 67/500\n",
            "453/453 [==============================] - 0s 586us/sample - loss: 2.6337 - accuracy: 0.4790\n",
            "Epoch 68/500\n",
            "453/453 [==============================] - 0s 659us/sample - loss: 2.6141 - accuracy: 0.4724\n",
            "Epoch 69/500\n",
            "453/453 [==============================] - 0s 659us/sample - loss: 2.5846 - accuracy: 0.4857\n",
            "Epoch 70/500\n",
            "453/453 [==============================] - 0s 632us/sample - loss: 2.5499 - accuracy: 0.4967\n",
            "Epoch 71/500\n",
            "453/453 [==============================] - 0s 649us/sample - loss: 2.5110 - accuracy: 0.5099\n",
            "Epoch 72/500\n",
            "453/453 [==============================] - 0s 624us/sample - loss: 2.5007 - accuracy: 0.5055\n",
            "Epoch 73/500\n",
            "453/453 [==============================] - 0s 674us/sample - loss: 2.4887 - accuracy: 0.5055\n",
            "Epoch 74/500\n",
            "453/453 [==============================] - 0s 637us/sample - loss: 2.4980 - accuracy: 0.5099\n",
            "Epoch 75/500\n",
            "453/453 [==============================] - 0s 642us/sample - loss: 2.4867 - accuracy: 0.5011\n",
            "Epoch 76/500\n",
            "453/453 [==============================] - 0s 635us/sample - loss: 2.4790 - accuracy: 0.5166\n",
            "Epoch 77/500\n",
            "453/453 [==============================] - 0s 612us/sample - loss: 2.4487 - accuracy: 0.5254\n",
            "Epoch 78/500\n",
            "453/453 [==============================] - 0s 633us/sample - loss: 2.5694 - accuracy: 0.4636\n",
            "Epoch 79/500\n",
            "453/453 [==============================] - 0s 633us/sample - loss: 2.4778 - accuracy: 0.5232\n",
            "Epoch 80/500\n",
            "453/453 [==============================] - 0s 641us/sample - loss: 2.3696 - accuracy: 0.5453\n",
            "Epoch 81/500\n",
            "453/453 [==============================] - 0s 674us/sample - loss: 2.3177 - accuracy: 0.5453\n",
            "Epoch 82/500\n",
            "453/453 [==============================] - 0s 648us/sample - loss: 2.2967 - accuracy: 0.5497\n",
            "Epoch 83/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 2.2630 - accuracy: 0.5563\n",
            "Epoch 84/500\n",
            "453/453 [==============================] - 0s 628us/sample - loss: 2.2169 - accuracy: 0.5762\n",
            "Epoch 85/500\n",
            "453/453 [==============================] - 0s 636us/sample - loss: 2.1929 - accuracy: 0.5872\n",
            "Epoch 86/500\n",
            "453/453 [==============================] - 0s 674us/sample - loss: 2.1701 - accuracy: 0.5806\n",
            "Epoch 87/500\n",
            "453/453 [==============================] - 0s 646us/sample - loss: 2.1559 - accuracy: 0.5828\n",
            "Epoch 88/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 2.1132 - accuracy: 0.5982\n",
            "Epoch 89/500\n",
            "453/453 [==============================] - 0s 629us/sample - loss: 2.0862 - accuracy: 0.5982\n",
            "Epoch 90/500\n",
            "453/453 [==============================] - 0s 635us/sample - loss: 2.0663 - accuracy: 0.6115\n",
            "Epoch 91/500\n",
            "453/453 [==============================] - 0s 669us/sample - loss: 2.0395 - accuracy: 0.6181\n",
            "Epoch 92/500\n",
            "453/453 [==============================] - 0s 617us/sample - loss: 2.0207 - accuracy: 0.6071\n",
            "Epoch 93/500\n",
            "453/453 [==============================] - 0s 626us/sample - loss: 1.9980 - accuracy: 0.6225\n",
            "Epoch 94/500\n",
            "453/453 [==============================] - 0s 654us/sample - loss: 1.9704 - accuracy: 0.6247\n",
            "Epoch 95/500\n",
            "453/453 [==============================] - 0s 652us/sample - loss: 1.9446 - accuracy: 0.6291\n",
            "Epoch 96/500\n",
            "453/453 [==============================] - 0s 652us/sample - loss: 1.9324 - accuracy: 0.6512\n",
            "Epoch 97/500\n",
            "453/453 [==============================] - 0s 660us/sample - loss: 1.9041 - accuracy: 0.6556\n",
            "Epoch 98/500\n",
            "453/453 [==============================] - 0s 595us/sample - loss: 1.8853 - accuracy: 0.6490\n",
            "Epoch 99/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 1.8620 - accuracy: 0.6689\n",
            "Epoch 100/500\n",
            "453/453 [==============================] - 0s 671us/sample - loss: 1.8399 - accuracy: 0.6733\n",
            "Epoch 101/500\n",
            "453/453 [==============================] - 0s 664us/sample - loss: 1.8186 - accuracy: 0.6711\n",
            "Epoch 102/500\n",
            "453/453 [==============================] - 0s 673us/sample - loss: 1.7980 - accuracy: 0.6887\n",
            "Epoch 103/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 1.7865 - accuracy: 0.6998\n",
            "Epoch 104/500\n",
            "453/453 [==============================] - 0s 747us/sample - loss: 1.7648 - accuracy: 0.6976\n",
            "Epoch 105/500\n",
            "453/453 [==============================] - 0s 661us/sample - loss: 1.7504 - accuracy: 0.6909\n",
            "Epoch 106/500\n",
            "453/453 [==============================] - 0s 672us/sample - loss: 1.7313 - accuracy: 0.7174\n",
            "Epoch 107/500\n",
            "453/453 [==============================] - 0s 666us/sample - loss: 1.7158 - accuracy: 0.7020\n",
            "Epoch 108/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 1.6898 - accuracy: 0.7108\n",
            "Epoch 109/500\n",
            "453/453 [==============================] - 0s 681us/sample - loss: 1.6714 - accuracy: 0.7196\n",
            "Epoch 110/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 1.6538 - accuracy: 0.7241\n",
            "Epoch 111/500\n",
            "453/453 [==============================] - 0s 646us/sample - loss: 1.6333 - accuracy: 0.7351\n",
            "Epoch 112/500\n",
            "453/453 [==============================] - 0s 644us/sample - loss: 1.6092 - accuracy: 0.7506\n",
            "Epoch 113/500\n",
            "453/453 [==============================] - 0s 675us/sample - loss: 1.5968 - accuracy: 0.7528\n",
            "Epoch 114/500\n",
            "453/453 [==============================] - 0s 683us/sample - loss: 1.5816 - accuracy: 0.7572\n",
            "Epoch 115/500\n",
            "453/453 [==============================] - 0s 616us/sample - loss: 1.5640 - accuracy: 0.7528\n",
            "Epoch 116/500\n",
            "453/453 [==============================] - 0s 644us/sample - loss: 1.5481 - accuracy: 0.7594\n",
            "Epoch 117/500\n",
            "453/453 [==============================] - 0s 649us/sample - loss: 1.5354 - accuracy: 0.7594\n",
            "Epoch 118/500\n",
            "453/453 [==============================] - 0s 628us/sample - loss: 1.5138 - accuracy: 0.7616\n",
            "Epoch 119/500\n",
            "453/453 [==============================] - 0s 650us/sample - loss: 1.4962 - accuracy: 0.7792\n",
            "Epoch 120/500\n",
            "453/453 [==============================] - 0s 669us/sample - loss: 1.4875 - accuracy: 0.7726\n",
            "Epoch 121/500\n",
            "453/453 [==============================] - 0s 645us/sample - loss: 1.4827 - accuracy: 0.7726\n",
            "Epoch 122/500\n",
            "453/453 [==============================] - 0s 643us/sample - loss: 1.4662 - accuracy: 0.7770\n",
            "Epoch 123/500\n",
            "453/453 [==============================] - 0s 609us/sample - loss: 1.4632 - accuracy: 0.7682\n",
            "Epoch 124/500\n",
            "453/453 [==============================] - 0s 673us/sample - loss: 1.4414 - accuracy: 0.7859\n",
            "Epoch 125/500\n",
            "453/453 [==============================] - 0s 630us/sample - loss: 1.4282 - accuracy: 0.7969\n",
            "Epoch 126/500\n",
            "453/453 [==============================] - 0s 642us/sample - loss: 1.4120 - accuracy: 0.7991\n",
            "Epoch 127/500\n",
            "453/453 [==============================] - 0s 673us/sample - loss: 1.4115 - accuracy: 0.7859\n",
            "Epoch 128/500\n",
            "453/453 [==============================] - 0s 635us/sample - loss: 1.3870 - accuracy: 0.8057\n",
            "Epoch 129/500\n",
            "453/453 [==============================] - 0s 699us/sample - loss: 1.3548 - accuracy: 0.8124\n",
            "Epoch 130/500\n",
            "453/453 [==============================] - 0s 640us/sample - loss: 1.3518 - accuracy: 0.8168\n",
            "Epoch 131/500\n",
            "453/453 [==============================] - 0s 711us/sample - loss: 1.3289 - accuracy: 0.8168\n",
            "Epoch 132/500\n",
            "453/453 [==============================] - 0s 664us/sample - loss: 1.3113 - accuracy: 0.8256\n",
            "Epoch 133/500\n",
            "453/453 [==============================] - 0s 613us/sample - loss: 1.3045 - accuracy: 0.8124\n",
            "Epoch 134/500\n",
            "453/453 [==============================] - 0s 635us/sample - loss: 1.2959 - accuracy: 0.8146\n",
            "Epoch 135/500\n",
            "453/453 [==============================] - 0s 642us/sample - loss: 1.2914 - accuracy: 0.8212\n",
            "Epoch 136/500\n",
            "453/453 [==============================] - 0s 623us/sample - loss: 1.2744 - accuracy: 0.8212\n",
            "Epoch 137/500\n",
            "453/453 [==============================] - 0s 645us/sample - loss: 1.2670 - accuracy: 0.8300\n",
            "Epoch 138/500\n",
            "453/453 [==============================] - 0s 651us/sample - loss: 1.2522 - accuracy: 0.8344\n",
            "Epoch 139/500\n",
            "453/453 [==============================] - 0s 601us/sample - loss: 1.2458 - accuracy: 0.8411\n",
            "Epoch 140/500\n",
            "453/453 [==============================] - 0s 671us/sample - loss: 1.2329 - accuracy: 0.8300\n",
            "Epoch 141/500\n",
            "453/453 [==============================] - 0s 664us/sample - loss: 1.2161 - accuracy: 0.8344\n",
            "Epoch 142/500\n",
            "453/453 [==============================] - 0s 634us/sample - loss: 1.1969 - accuracy: 0.8477\n",
            "Epoch 143/500\n",
            "453/453 [==============================] - 0s 634us/sample - loss: 1.1802 - accuracy: 0.8389\n",
            "Epoch 144/500\n",
            "453/453 [==============================] - 0s 619us/sample - loss: 1.1908 - accuracy: 0.8322\n",
            "Epoch 145/500\n",
            "453/453 [==============================] - 0s 661us/sample - loss: 1.1759 - accuracy: 0.8389\n",
            "Epoch 146/500\n",
            "453/453 [==============================] - 0s 628us/sample - loss: 1.1641 - accuracy: 0.8499\n",
            "Epoch 147/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 1.1496 - accuracy: 0.8455\n",
            "Epoch 148/500\n",
            "453/453 [==============================] - 0s 632us/sample - loss: 1.1413 - accuracy: 0.8411\n",
            "Epoch 149/500\n",
            "453/453 [==============================] - 0s 652us/sample - loss: 1.1283 - accuracy: 0.8499\n",
            "Epoch 150/500\n",
            "453/453 [==============================] - 0s 582us/sample - loss: 1.1164 - accuracy: 0.8565\n",
            "Epoch 151/500\n",
            "453/453 [==============================] - 0s 637us/sample - loss: 1.1028 - accuracy: 0.8698\n",
            "Epoch 152/500\n",
            "453/453 [==============================] - 0s 634us/sample - loss: 1.0868 - accuracy: 0.8764\n",
            "Epoch 153/500\n",
            "453/453 [==============================] - 0s 667us/sample - loss: 1.0776 - accuracy: 0.8742\n",
            "Epoch 154/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 1.0594 - accuracy: 0.8742\n",
            "Epoch 155/500\n",
            "453/453 [==============================] - 0s 683us/sample - loss: 1.0576 - accuracy: 0.8675\n",
            "Epoch 156/500\n",
            "453/453 [==============================] - 0s 666us/sample - loss: 1.0585 - accuracy: 0.8609\n",
            "Epoch 157/500\n",
            "453/453 [==============================] - 0s 699us/sample - loss: 1.0499 - accuracy: 0.8587\n",
            "Epoch 158/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 1.0353 - accuracy: 0.8587\n",
            "Epoch 159/500\n",
            "453/453 [==============================] - 0s 684us/sample - loss: 1.0262 - accuracy: 0.8675\n",
            "Epoch 160/500\n",
            "453/453 [==============================] - 0s 626us/sample - loss: 1.0182 - accuracy: 0.8764\n",
            "Epoch 161/500\n",
            "453/453 [==============================] - 0s 657us/sample - loss: 1.0010 - accuracy: 0.8808\n",
            "Epoch 162/500\n",
            "453/453 [==============================] - 0s 666us/sample - loss: 1.0046 - accuracy: 0.8764\n",
            "Epoch 163/500\n",
            "453/453 [==============================] - 0s 641us/sample - loss: 0.9847 - accuracy: 0.8918\n",
            "Epoch 164/500\n",
            "453/453 [==============================] - 0s 677us/sample - loss: 0.9716 - accuracy: 0.8830\n",
            "Epoch 165/500\n",
            "453/453 [==============================] - 0s 688us/sample - loss: 0.9823 - accuracy: 0.8742\n",
            "Epoch 166/500\n",
            "453/453 [==============================] - 0s 641us/sample - loss: 0.9692 - accuracy: 0.8808\n",
            "Epoch 167/500\n",
            "453/453 [==============================] - 0s 649us/sample - loss: 0.9431 - accuracy: 0.8830\n",
            "Epoch 168/500\n",
            "453/453 [==============================] - 0s 654us/sample - loss: 0.9314 - accuracy: 0.8830\n",
            "Epoch 169/500\n",
            "453/453 [==============================] - 0s 668us/sample - loss: 0.9228 - accuracy: 0.8852\n",
            "Epoch 170/500\n",
            "453/453 [==============================] - 0s 673us/sample - loss: 0.9116 - accuracy: 0.8874\n",
            "Epoch 171/500\n",
            "453/453 [==============================] - 0s 593us/sample - loss: 0.8993 - accuracy: 0.8830\n",
            "Epoch 172/500\n",
            "453/453 [==============================] - 0s 702us/sample - loss: 0.8885 - accuracy: 0.8830\n",
            "Epoch 173/500\n",
            "453/453 [==============================] - 0s 609us/sample - loss: 0.8760 - accuracy: 0.8962\n",
            "Epoch 174/500\n",
            "453/453 [==============================] - 0s 612us/sample - loss: 0.8664 - accuracy: 0.8962\n",
            "Epoch 175/500\n",
            "453/453 [==============================] - 0s 625us/sample - loss: 0.8564 - accuracy: 0.8940\n",
            "Epoch 176/500\n",
            "453/453 [==============================] - 0s 661us/sample - loss: 0.8472 - accuracy: 0.9029\n",
            "Epoch 177/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 0.8371 - accuracy: 0.9095\n",
            "Epoch 178/500\n",
            "453/453 [==============================] - 0s 652us/sample - loss: 0.8288 - accuracy: 0.9051\n",
            "Epoch 179/500\n",
            "453/453 [==============================] - 0s 682us/sample - loss: 0.8198 - accuracy: 0.9139\n",
            "Epoch 180/500\n",
            "453/453 [==============================] - 0s 615us/sample - loss: 0.8121 - accuracy: 0.9073\n",
            "Epoch 181/500\n",
            "453/453 [==============================] - 0s 644us/sample - loss: 0.8063 - accuracy: 0.9117\n",
            "Epoch 182/500\n",
            "453/453 [==============================] - 0s 612us/sample - loss: 0.7965 - accuracy: 0.9183\n",
            "Epoch 183/500\n",
            "453/453 [==============================] - 0s 646us/sample - loss: 0.7894 - accuracy: 0.9139\n",
            "Epoch 184/500\n",
            "453/453 [==============================] - 0s 634us/sample - loss: 0.7842 - accuracy: 0.9161\n",
            "Epoch 185/500\n",
            "453/453 [==============================] - 0s 644us/sample - loss: 0.7760 - accuracy: 0.9205\n",
            "Epoch 186/500\n",
            "453/453 [==============================] - 0s 675us/sample - loss: 0.7696 - accuracy: 0.9161\n",
            "Epoch 187/500\n",
            "453/453 [==============================] - 0s 659us/sample - loss: 0.7611 - accuracy: 0.9183\n",
            "Epoch 188/500\n",
            "453/453 [==============================] - 0s 625us/sample - loss: 0.7545 - accuracy: 0.9117\n",
            "Epoch 189/500\n",
            "453/453 [==============================] - 0s 619us/sample - loss: 0.7471 - accuracy: 0.9161\n",
            "Epoch 190/500\n",
            "453/453 [==============================] - 0s 648us/sample - loss: 0.7398 - accuracy: 0.9139\n",
            "Epoch 191/500\n",
            "453/453 [==============================] - 0s 620us/sample - loss: 0.7337 - accuracy: 0.9139\n",
            "Epoch 192/500\n",
            "453/453 [==============================] - 0s 626us/sample - loss: 0.7280 - accuracy: 0.9227\n",
            "Epoch 193/500\n",
            "453/453 [==============================] - 0s 683us/sample - loss: 0.7207 - accuracy: 0.9249\n",
            "Epoch 194/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 0.7130 - accuracy: 0.9249\n",
            "Epoch 195/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 0.7071 - accuracy: 0.9249\n",
            "Epoch 196/500\n",
            "453/453 [==============================] - 0s 606us/sample - loss: 0.6998 - accuracy: 0.9249\n",
            "Epoch 197/500\n",
            "453/453 [==============================] - 0s 658us/sample - loss: 0.6934 - accuracy: 0.9294\n",
            "Epoch 198/500\n",
            "453/453 [==============================] - 0s 609us/sample - loss: 0.6911 - accuracy: 0.9294\n",
            "Epoch 199/500\n",
            "453/453 [==============================] - 0s 645us/sample - loss: 0.6826 - accuracy: 0.9294\n",
            "Epoch 200/500\n",
            "453/453 [==============================] - 0s 676us/sample - loss: 0.6778 - accuracy: 0.9249\n",
            "Epoch 201/500\n",
            "453/453 [==============================] - 0s 688us/sample - loss: 0.6746 - accuracy: 0.9294\n",
            "Epoch 202/500\n",
            "453/453 [==============================] - 0s 618us/sample - loss: 0.6913 - accuracy: 0.9227\n",
            "Epoch 203/500\n",
            "453/453 [==============================] - 0s 661us/sample - loss: 0.7098 - accuracy: 0.9161\n",
            "Epoch 204/500\n",
            "453/453 [==============================] - 0s 669us/sample - loss: 0.6969 - accuracy: 0.9161\n",
            "Epoch 205/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 0.6712 - accuracy: 0.9183\n",
            "Epoch 206/500\n",
            "453/453 [==============================] - 0s 678us/sample - loss: 0.6647 - accuracy: 0.9227\n",
            "Epoch 207/500\n",
            "453/453 [==============================] - 0s 683us/sample - loss: 0.6553 - accuracy: 0.9249\n",
            "Epoch 208/500\n",
            "453/453 [==============================] - 0s 671us/sample - loss: 0.6512 - accuracy: 0.9249\n",
            "Epoch 209/500\n",
            "453/453 [==============================] - 0s 630us/sample - loss: 0.6516 - accuracy: 0.9183\n",
            "Epoch 210/500\n",
            "453/453 [==============================] - 0s 672us/sample - loss: 0.6834 - accuracy: 0.9139\n",
            "Epoch 211/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 0.6890 - accuracy: 0.9095\n",
            "Epoch 212/500\n",
            "453/453 [==============================] - 0s 660us/sample - loss: 0.7172 - accuracy: 0.8985\n",
            "Epoch 213/500\n",
            "453/453 [==============================] - 0s 661us/sample - loss: 0.7097 - accuracy: 0.8896\n",
            "Epoch 214/500\n",
            "453/453 [==============================] - 0s 692us/sample - loss: 0.6732 - accuracy: 0.8985\n",
            "Epoch 215/500\n",
            "453/453 [==============================] - 0s 596us/sample - loss: 0.6580 - accuracy: 0.9095\n",
            "Epoch 216/500\n",
            "453/453 [==============================] - 0s 627us/sample - loss: 0.6461 - accuracy: 0.9183\n",
            "Epoch 217/500\n",
            "453/453 [==============================] - 0s 622us/sample - loss: 0.6314 - accuracy: 0.9249\n",
            "Epoch 218/500\n",
            "453/453 [==============================] - 0s 621us/sample - loss: 0.6170 - accuracy: 0.9249\n",
            "Epoch 219/500\n",
            "453/453 [==============================] - 0s 678us/sample - loss: 0.6104 - accuracy: 0.9205\n",
            "Epoch 220/500\n",
            "453/453 [==============================] - 0s 645us/sample - loss: 0.5947 - accuracy: 0.9249\n",
            "Epoch 221/500\n",
            "453/453 [==============================] - 0s 669us/sample - loss: 0.5897 - accuracy: 0.9316\n",
            "Epoch 222/500\n",
            "453/453 [==============================] - 0s 624us/sample - loss: 0.5881 - accuracy: 0.9227\n",
            "Epoch 223/500\n",
            "453/453 [==============================] - 0s 616us/sample - loss: 0.5794 - accuracy: 0.9249\n",
            "Epoch 224/500\n",
            "453/453 [==============================] - 0s 661us/sample - loss: 0.5790 - accuracy: 0.9205\n",
            "Epoch 225/500\n",
            "453/453 [==============================] - 0s 627us/sample - loss: 0.5862 - accuracy: 0.9205\n",
            "Epoch 226/500\n",
            "453/453 [==============================] - 0s 664us/sample - loss: 0.5954 - accuracy: 0.9205\n",
            "Epoch 227/500\n",
            "453/453 [==============================] - 0s 665us/sample - loss: 0.5855 - accuracy: 0.9227\n",
            "Epoch 228/500\n",
            "453/453 [==============================] - 0s 690us/sample - loss: 0.5752 - accuracy: 0.9316\n",
            "Epoch 229/500\n",
            "453/453 [==============================] - 0s 583us/sample - loss: 0.5622 - accuracy: 0.9316\n",
            "Epoch 230/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 0.5605 - accuracy: 0.9249\n",
            "Epoch 231/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 0.5596 - accuracy: 0.9227\n",
            "Epoch 232/500\n",
            "453/453 [==============================] - 0s 652us/sample - loss: 0.5512 - accuracy: 0.9205\n",
            "Epoch 233/500\n",
            "453/453 [==============================] - 0s 630us/sample - loss: 0.5318 - accuracy: 0.9294\n",
            "Epoch 234/500\n",
            "453/453 [==============================] - 0s 661us/sample - loss: 0.5448 - accuracy: 0.9294\n",
            "Epoch 235/500\n",
            "453/453 [==============================] - 0s 633us/sample - loss: 0.5514 - accuracy: 0.9249\n",
            "Epoch 236/500\n",
            "453/453 [==============================] - 0s 594us/sample - loss: 0.5263 - accuracy: 0.9249\n",
            "Epoch 237/500\n",
            "453/453 [==============================] - 0s 672us/sample - loss: 0.5153 - accuracy: 0.9360\n",
            "Epoch 238/500\n",
            "453/453 [==============================] - 0s 619us/sample - loss: 0.5064 - accuracy: 0.9404\n",
            "Epoch 239/500\n",
            "453/453 [==============================] - 0s 655us/sample - loss: 0.4990 - accuracy: 0.9404\n",
            "Epoch 240/500\n",
            "453/453 [==============================] - 0s 625us/sample - loss: 0.4966 - accuracy: 0.9360\n",
            "Epoch 241/500\n",
            "453/453 [==============================] - 0s 648us/sample - loss: 0.4898 - accuracy: 0.9382\n",
            "Epoch 242/500\n",
            "453/453 [==============================] - 0s 687us/sample - loss: 0.4862 - accuracy: 0.9404\n",
            "Epoch 243/500\n",
            "453/453 [==============================] - 0s 633us/sample - loss: 0.4814 - accuracy: 0.9338\n",
            "Epoch 244/500\n",
            "453/453 [==============================] - 0s 618us/sample - loss: 0.4781 - accuracy: 0.9404\n",
            "Epoch 245/500\n",
            "453/453 [==============================] - 0s 642us/sample - loss: 0.4717 - accuracy: 0.9382\n",
            "Epoch 246/500\n",
            "453/453 [==============================] - 0s 645us/sample - loss: 0.4681 - accuracy: 0.9382\n",
            "Epoch 247/500\n",
            "453/453 [==============================] - 0s 640us/sample - loss: 0.4635 - accuracy: 0.9382\n",
            "Epoch 248/500\n",
            "453/453 [==============================] - 0s 665us/sample - loss: 0.4599 - accuracy: 0.9382\n",
            "Epoch 249/500\n",
            "453/453 [==============================] - 0s 625us/sample - loss: 0.4565 - accuracy: 0.9338\n",
            "Epoch 250/500\n",
            "453/453 [==============================] - 0s 661us/sample - loss: 0.4519 - accuracy: 0.9426\n",
            "Epoch 251/500\n",
            "453/453 [==============================] - 0s 614us/sample - loss: 0.4476 - accuracy: 0.9448\n",
            "Epoch 252/500\n",
            "453/453 [==============================] - 0s 645us/sample - loss: 0.4455 - accuracy: 0.9448\n",
            "Epoch 253/500\n",
            "453/453 [==============================] - 0s 665us/sample - loss: 0.4439 - accuracy: 0.9448\n",
            "Epoch 254/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 0.4392 - accuracy: 0.9426\n",
            "Epoch 255/500\n",
            "453/453 [==============================] - 0s 652us/sample - loss: 0.4355 - accuracy: 0.9448\n",
            "Epoch 256/500\n",
            "453/453 [==============================] - 0s 646us/sample - loss: 0.4326 - accuracy: 0.9426\n",
            "Epoch 257/500\n",
            "453/453 [==============================] - 0s 630us/sample - loss: 0.4297 - accuracy: 0.9360\n",
            "Epoch 258/500\n",
            "453/453 [==============================] - 0s 646us/sample - loss: 0.4259 - accuracy: 0.9426\n",
            "Epoch 259/500\n",
            "453/453 [==============================] - 0s 626us/sample - loss: 0.4225 - accuracy: 0.9404\n",
            "Epoch 260/500\n",
            "453/453 [==============================] - 0s 663us/sample - loss: 0.4292 - accuracy: 0.9382\n",
            "Epoch 261/500\n",
            "453/453 [==============================] - 0s 695us/sample - loss: 0.4179 - accuracy: 0.9382\n",
            "Epoch 262/500\n",
            "453/453 [==============================] - 0s 682us/sample - loss: 0.4157 - accuracy: 0.9382\n",
            "Epoch 263/500\n",
            "453/453 [==============================] - 0s 642us/sample - loss: 0.4185 - accuracy: 0.9404\n",
            "Epoch 264/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 0.4095 - accuracy: 0.9426\n",
            "Epoch 265/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 0.4056 - accuracy: 0.9448\n",
            "Epoch 266/500\n",
            "453/453 [==============================] - 0s 666us/sample - loss: 0.4014 - accuracy: 0.9448\n",
            "Epoch 267/500\n",
            "453/453 [==============================] - 0s 671us/sample - loss: 0.3987 - accuracy: 0.9448\n",
            "Epoch 268/500\n",
            "453/453 [==============================] - 0s 657us/sample - loss: 0.3954 - accuracy: 0.9448\n",
            "Epoch 269/500\n",
            "453/453 [==============================] - 0s 675us/sample - loss: 0.3933 - accuracy: 0.9426\n",
            "Epoch 270/500\n",
            "453/453 [==============================] - 0s 654us/sample - loss: 0.3914 - accuracy: 0.9448\n",
            "Epoch 271/500\n",
            "453/453 [==============================] - 0s 659us/sample - loss: 0.3894 - accuracy: 0.9470\n",
            "Epoch 272/500\n",
            "453/453 [==============================] - 0s 617us/sample - loss: 0.3854 - accuracy: 0.9470\n",
            "Epoch 273/500\n",
            "453/453 [==============================] - 0s 660us/sample - loss: 0.3892 - accuracy: 0.9492\n",
            "Epoch 274/500\n",
            "453/453 [==============================] - 0s 672us/sample - loss: 0.3902 - accuracy: 0.9470\n",
            "Epoch 275/500\n",
            "453/453 [==============================] - 0s 643us/sample - loss: 0.4001 - accuracy: 0.9426\n",
            "Epoch 276/500\n",
            "453/453 [==============================] - 0s 645us/sample - loss: 0.4517 - accuracy: 0.9316\n",
            "Epoch 277/500\n",
            "453/453 [==============================] - 0s 631us/sample - loss: 0.4279 - accuracy: 0.9272\n",
            "Epoch 278/500\n",
            "453/453 [==============================] - 0s 642us/sample - loss: 0.3988 - accuracy: 0.9426\n",
            "Epoch 279/500\n",
            "453/453 [==============================] - 0s 666us/sample - loss: 0.3964 - accuracy: 0.9404\n",
            "Epoch 280/500\n",
            "453/453 [==============================] - 0s 698us/sample - loss: 0.4370 - accuracy: 0.9338\n",
            "Epoch 281/500\n",
            "453/453 [==============================] - 0s 695us/sample - loss: 0.4133 - accuracy: 0.9426\n",
            "Epoch 282/500\n",
            "453/453 [==============================] - 0s 624us/sample - loss: 0.3838 - accuracy: 0.9448\n",
            "Epoch 283/500\n",
            "453/453 [==============================] - 0s 646us/sample - loss: 0.3727 - accuracy: 0.9470\n",
            "Epoch 284/500\n",
            "453/453 [==============================] - 0s 619us/sample - loss: 0.3669 - accuracy: 0.9470\n",
            "Epoch 285/500\n",
            "453/453 [==============================] - 0s 619us/sample - loss: 0.3626 - accuracy: 0.9448\n",
            "Epoch 286/500\n",
            "453/453 [==============================] - 0s 700us/sample - loss: 0.3596 - accuracy: 0.9426\n",
            "Epoch 287/500\n",
            "453/453 [==============================] - 0s 631us/sample - loss: 0.3557 - accuracy: 0.9426\n",
            "Epoch 288/500\n",
            "453/453 [==============================] - 0s 652us/sample - loss: 0.3524 - accuracy: 0.9470\n",
            "Epoch 289/500\n",
            "453/453 [==============================] - 0s 616us/sample - loss: 0.3500 - accuracy: 0.9426\n",
            "Epoch 290/500\n",
            "453/453 [==============================] - 0s 682us/sample - loss: 0.3478 - accuracy: 0.9426\n",
            "Epoch 291/500\n",
            "453/453 [==============================] - 0s 676us/sample - loss: 0.3444 - accuracy: 0.9492\n",
            "Epoch 292/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 0.3447 - accuracy: 0.9404\n",
            "Epoch 293/500\n",
            "453/453 [==============================] - 0s 691us/sample - loss: 0.3419 - accuracy: 0.9448\n",
            "Epoch 294/500\n",
            "453/453 [==============================] - 0s 647us/sample - loss: 0.3431 - accuracy: 0.9492\n",
            "Epoch 295/500\n",
            "453/453 [==============================] - 0s 648us/sample - loss: 0.3387 - accuracy: 0.9426\n",
            "Epoch 296/500\n",
            "453/453 [==============================] - 0s 623us/sample - loss: 0.3378 - accuracy: 0.9426\n",
            "Epoch 297/500\n",
            "453/453 [==============================] - 0s 668us/sample - loss: 0.3373 - accuracy: 0.9382\n",
            "Epoch 298/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 0.3422 - accuracy: 0.9426\n",
            "Epoch 299/500\n",
            "453/453 [==============================] - 0s 676us/sample - loss: 0.3588 - accuracy: 0.9360\n",
            "Epoch 300/500\n",
            "453/453 [==============================] - 0s 658us/sample - loss: 0.3490 - accuracy: 0.9382\n",
            "Epoch 301/500\n",
            "453/453 [==============================] - 0s 654us/sample - loss: 0.3367 - accuracy: 0.9426\n",
            "Epoch 302/500\n",
            "453/453 [==============================] - 0s 602us/sample - loss: 0.3380 - accuracy: 0.9382\n",
            "Epoch 303/500\n",
            "453/453 [==============================] - 0s 610us/sample - loss: 0.3310 - accuracy: 0.9426\n",
            "Epoch 304/500\n",
            "453/453 [==============================] - 0s 686us/sample - loss: 0.3282 - accuracy: 0.9404\n",
            "Epoch 305/500\n",
            "453/453 [==============================] - 0s 646us/sample - loss: 0.3273 - accuracy: 0.9448\n",
            "Epoch 306/500\n",
            "453/453 [==============================] - 0s 665us/sample - loss: 0.3203 - accuracy: 0.9448\n",
            "Epoch 307/500\n",
            "453/453 [==============================] - 0s 654us/sample - loss: 0.3161 - accuracy: 0.9492\n",
            "Epoch 308/500\n",
            "453/453 [==============================] - 0s 631us/sample - loss: 0.3141 - accuracy: 0.9470\n",
            "Epoch 309/500\n",
            "453/453 [==============================] - 0s 615us/sample - loss: 0.3119 - accuracy: 0.9426\n",
            "Epoch 310/500\n",
            "453/453 [==============================] - 0s 605us/sample - loss: 0.3099 - accuracy: 0.9470\n",
            "Epoch 311/500\n",
            "453/453 [==============================] - 0s 677us/sample - loss: 0.3074 - accuracy: 0.9448\n",
            "Epoch 312/500\n",
            "453/453 [==============================] - 0s 651us/sample - loss: 0.3048 - accuracy: 0.9448\n",
            "Epoch 313/500\n",
            "453/453 [==============================] - 0s 702us/sample - loss: 0.3021 - accuracy: 0.9492\n",
            "Epoch 314/500\n",
            "453/453 [==============================] - 0s 635us/sample - loss: 0.3068 - accuracy: 0.9492\n",
            "Epoch 315/500\n",
            "453/453 [==============================] - 0s 627us/sample - loss: 0.3015 - accuracy: 0.9492\n",
            "Epoch 316/500\n",
            "453/453 [==============================] - 0s 609us/sample - loss: 0.2967 - accuracy: 0.9492\n",
            "Epoch 317/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 0.2934 - accuracy: 0.9492\n",
            "Epoch 318/500\n",
            "453/453 [==============================] - 0s 637us/sample - loss: 0.2914 - accuracy: 0.9470\n",
            "Epoch 319/500\n",
            "453/453 [==============================] - 0s 627us/sample - loss: 0.2890 - accuracy: 0.9514\n",
            "Epoch 320/500\n",
            "453/453 [==============================] - 0s 671us/sample - loss: 0.2868 - accuracy: 0.9514\n",
            "Epoch 321/500\n",
            "453/453 [==============================] - 0s 676us/sample - loss: 0.2853 - accuracy: 0.9470\n",
            "Epoch 322/500\n",
            "453/453 [==============================] - 0s 607us/sample - loss: 0.2826 - accuracy: 0.9514\n",
            "Epoch 323/500\n",
            "453/453 [==============================] - 0s 612us/sample - loss: 0.2810 - accuracy: 0.9514\n",
            "Epoch 324/500\n",
            "453/453 [==============================] - 0s 669us/sample - loss: 0.2802 - accuracy: 0.9492\n",
            "Epoch 325/500\n",
            "453/453 [==============================] - 0s 621us/sample - loss: 0.2776 - accuracy: 0.9470\n",
            "Epoch 326/500\n",
            "453/453 [==============================] - 0s 675us/sample - loss: 0.2786 - accuracy: 0.9514\n",
            "Epoch 327/500\n",
            "453/453 [==============================] - 0s 677us/sample - loss: 0.2747 - accuracy: 0.9514\n",
            "Epoch 328/500\n",
            "453/453 [==============================] - 0s 657us/sample - loss: 0.2736 - accuracy: 0.9448\n",
            "Epoch 329/500\n",
            "453/453 [==============================] - 0s 607us/sample - loss: 0.2707 - accuracy: 0.9492\n",
            "Epoch 330/500\n",
            "453/453 [==============================] - 0s 625us/sample - loss: 0.2690 - accuracy: 0.9514\n",
            "Epoch 331/500\n",
            "453/453 [==============================] - 0s 644us/sample - loss: 0.2680 - accuracy: 0.9470\n",
            "Epoch 332/500\n",
            "453/453 [==============================] - 0s 600us/sample - loss: 0.2657 - accuracy: 0.9448\n",
            "Epoch 333/500\n",
            "453/453 [==============================] - 0s 671us/sample - loss: 0.2692 - accuracy: 0.9514\n",
            "Epoch 334/500\n",
            "453/453 [==============================] - 0s 668us/sample - loss: 0.2664 - accuracy: 0.9492\n",
            "Epoch 335/500\n",
            "453/453 [==============================] - 0s 679us/sample - loss: 0.2660 - accuracy: 0.9492\n",
            "Epoch 336/500\n",
            "453/453 [==============================] - 0s 641us/sample - loss: 0.2621 - accuracy: 0.9492\n",
            "Epoch 337/500\n",
            "453/453 [==============================] - 0s 614us/sample - loss: 0.2610 - accuracy: 0.9492\n",
            "Epoch 338/500\n",
            "453/453 [==============================] - 0s 664us/sample - loss: 0.2608 - accuracy: 0.9470\n",
            "Epoch 339/500\n",
            "453/453 [==============================] - 0s 629us/sample - loss: 0.2629 - accuracy: 0.9492\n",
            "Epoch 340/500\n",
            "453/453 [==============================] - 0s 676us/sample - loss: 0.3213 - accuracy: 0.9382\n",
            "Epoch 341/500\n",
            "453/453 [==============================] - 0s 643us/sample - loss: 0.3599 - accuracy: 0.9316\n",
            "Epoch 342/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 0.3141 - accuracy: 0.9338\n",
            "Epoch 343/500\n",
            "453/453 [==============================] - 0s 629us/sample - loss: 0.2935 - accuracy: 0.9404\n",
            "Epoch 344/500\n",
            "453/453 [==============================] - 0s 636us/sample - loss: 0.2793 - accuracy: 0.9404\n",
            "Epoch 345/500\n",
            "453/453 [==============================] - 0s 665us/sample - loss: 0.2783 - accuracy: 0.9404\n",
            "Epoch 346/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 0.2694 - accuracy: 0.9492\n",
            "Epoch 347/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 0.2641 - accuracy: 0.9514\n",
            "Epoch 348/500\n",
            "453/453 [==============================] - 0s 651us/sample - loss: 0.2584 - accuracy: 0.9492\n",
            "Epoch 349/500\n",
            "453/453 [==============================] - 0s 663us/sample - loss: 0.2535 - accuracy: 0.9514\n",
            "Epoch 350/500\n",
            "453/453 [==============================] - 0s 584us/sample - loss: 0.2498 - accuracy: 0.9514\n",
            "Epoch 351/500\n",
            "453/453 [==============================] - 0s 602us/sample - loss: 0.2472 - accuracy: 0.9514\n",
            "Epoch 352/500\n",
            "453/453 [==============================] - 0s 648us/sample - loss: 0.2429 - accuracy: 0.9492\n",
            "Epoch 353/500\n",
            "453/453 [==============================] - 0s 635us/sample - loss: 0.2403 - accuracy: 0.9470\n",
            "Epoch 354/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 0.2396 - accuracy: 0.9492\n",
            "Epoch 355/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 0.2381 - accuracy: 0.9448\n",
            "Epoch 356/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 0.2364 - accuracy: 0.9492\n",
            "Epoch 357/500\n",
            "453/453 [==============================] - 0s 629us/sample - loss: 0.2340 - accuracy: 0.9470\n",
            "Epoch 358/500\n",
            "453/453 [==============================] - 0s 644us/sample - loss: 0.2328 - accuracy: 0.9514\n",
            "Epoch 359/500\n",
            "453/453 [==============================] - 0s 675us/sample - loss: 0.2316 - accuracy: 0.9514\n",
            "Epoch 360/500\n",
            "453/453 [==============================] - 0s 648us/sample - loss: 0.2321 - accuracy: 0.9492\n",
            "Epoch 361/500\n",
            "453/453 [==============================] - 0s 667us/sample - loss: 0.2307 - accuracy: 0.9492\n",
            "Epoch 362/500\n",
            "453/453 [==============================] - 0s 659us/sample - loss: 0.2282 - accuracy: 0.9536\n",
            "Epoch 363/500\n",
            "453/453 [==============================] - 0s 663us/sample - loss: 0.2275 - accuracy: 0.9470\n",
            "Epoch 364/500\n",
            "453/453 [==============================] - 0s 625us/sample - loss: 0.2255 - accuracy: 0.9492\n",
            "Epoch 365/500\n",
            "453/453 [==============================] - 0s 582us/sample - loss: 0.2237 - accuracy: 0.9514\n",
            "Epoch 366/500\n",
            "453/453 [==============================] - 0s 657us/sample - loss: 0.2232 - accuracy: 0.9470\n",
            "Epoch 367/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 0.2213 - accuracy: 0.9492\n",
            "Epoch 368/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 0.2200 - accuracy: 0.9492\n",
            "Epoch 369/500\n",
            "453/453 [==============================] - 0s 673us/sample - loss: 0.2192 - accuracy: 0.9470\n",
            "Epoch 370/500\n",
            "453/453 [==============================] - 0s 643us/sample - loss: 0.2173 - accuracy: 0.9448\n",
            "Epoch 371/500\n",
            "453/453 [==============================] - 0s 620us/sample - loss: 0.2171 - accuracy: 0.9514\n",
            "Epoch 372/500\n",
            "453/453 [==============================] - 0s 609us/sample - loss: 0.2154 - accuracy: 0.9448\n",
            "Epoch 373/500\n",
            "453/453 [==============================] - 0s 659us/sample - loss: 0.2151 - accuracy: 0.9448\n",
            "Epoch 374/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 0.2217 - accuracy: 0.9470\n",
            "Epoch 375/500\n",
            "453/453 [==============================] - 0s 649us/sample - loss: 0.2200 - accuracy: 0.9448\n",
            "Epoch 376/500\n",
            "453/453 [==============================] - 0s 676us/sample - loss: 0.2225 - accuracy: 0.9404\n",
            "Epoch 377/500\n",
            "453/453 [==============================] - 0s 608us/sample - loss: 0.2161 - accuracy: 0.9382\n",
            "Epoch 378/500\n",
            "453/453 [==============================] - 0s 635us/sample - loss: 0.2140 - accuracy: 0.9470\n",
            "Epoch 379/500\n",
            "453/453 [==============================] - 0s 620us/sample - loss: 0.2129 - accuracy: 0.9448\n",
            "Epoch 380/500\n",
            "453/453 [==============================] - 0s 668us/sample - loss: 0.2114 - accuracy: 0.9404\n",
            "Epoch 381/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 0.2087 - accuracy: 0.9492\n",
            "Epoch 382/500\n",
            "453/453 [==============================] - 0s 659us/sample - loss: 0.2068 - accuracy: 0.9492\n",
            "Epoch 383/500\n",
            "453/453 [==============================] - 0s 658us/sample - loss: 0.2046 - accuracy: 0.9470\n",
            "Epoch 384/500\n",
            "453/453 [==============================] - 0s 607us/sample - loss: 0.2060 - accuracy: 0.9448\n",
            "Epoch 385/500\n",
            "453/453 [==============================] - 0s 604us/sample - loss: 0.2035 - accuracy: 0.9470\n",
            "Epoch 386/500\n",
            "453/453 [==============================] - 0s 626us/sample - loss: 0.2032 - accuracy: 0.9492\n",
            "Epoch 387/500\n",
            "453/453 [==============================] - 0s 621us/sample - loss: 0.2014 - accuracy: 0.9514\n",
            "Epoch 388/500\n",
            "453/453 [==============================] - 0s 667us/sample - loss: 0.2006 - accuracy: 0.9470\n",
            "Epoch 389/500\n",
            "453/453 [==============================] - 0s 706us/sample - loss: 0.2005 - accuracy: 0.9448\n",
            "Epoch 390/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 0.1988 - accuracy: 0.9470\n",
            "Epoch 391/500\n",
            "453/453 [==============================] - 0s 614us/sample - loss: 0.1967 - accuracy: 0.9514\n",
            "Epoch 392/500\n",
            "453/453 [==============================] - 0s 599us/sample - loss: 0.1953 - accuracy: 0.9514\n",
            "Epoch 393/500\n",
            "453/453 [==============================] - 0s 602us/sample - loss: 0.1956 - accuracy: 0.9514\n",
            "Epoch 394/500\n",
            "453/453 [==============================] - 0s 665us/sample - loss: 0.1944 - accuracy: 0.9448\n",
            "Epoch 395/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 0.1976 - accuracy: 0.9492\n",
            "Epoch 396/500\n",
            "453/453 [==============================] - 0s 657us/sample - loss: 0.1944 - accuracy: 0.9492\n",
            "Epoch 397/500\n",
            "453/453 [==============================] - 0s 688us/sample - loss: 0.1925 - accuracy: 0.9514\n",
            "Epoch 398/500\n",
            "453/453 [==============================] - 0s 626us/sample - loss: 0.1912 - accuracy: 0.9470\n",
            "Epoch 399/500\n",
            "453/453 [==============================] - 0s 606us/sample - loss: 0.1901 - accuracy: 0.9448\n",
            "Epoch 400/500\n",
            "453/453 [==============================] - 0s 632us/sample - loss: 0.1884 - accuracy: 0.9448\n",
            "Epoch 401/500\n",
            "453/453 [==============================] - 0s 636us/sample - loss: 0.1875 - accuracy: 0.9514\n",
            "Epoch 402/500\n",
            "453/453 [==============================] - 0s 664us/sample - loss: 0.1882 - accuracy: 0.9448\n",
            "Epoch 403/500\n",
            "453/453 [==============================] - 0s 678us/sample - loss: 0.1862 - accuracy: 0.9448\n",
            "Epoch 404/500\n",
            "453/453 [==============================] - 0s 658us/sample - loss: 0.1863 - accuracy: 0.9470\n",
            "Epoch 405/500\n",
            "453/453 [==============================] - 0s 626us/sample - loss: 0.1930 - accuracy: 0.9470\n",
            "Epoch 406/500\n",
            "453/453 [==============================] - 0s 613us/sample - loss: 0.1852 - accuracy: 0.9470\n",
            "Epoch 407/500\n",
            "453/453 [==============================] - 0s 617us/sample - loss: 0.1835 - accuracy: 0.9492\n",
            "Epoch 408/500\n",
            "453/453 [==============================] - 0s 673us/sample - loss: 0.1822 - accuracy: 0.9426\n",
            "Epoch 409/500\n",
            "453/453 [==============================] - 0s 676us/sample - loss: 0.1815 - accuracy: 0.9536\n",
            "Epoch 410/500\n",
            "453/453 [==============================] - 0s 667us/sample - loss: 0.1805 - accuracy: 0.9492\n",
            "Epoch 411/500\n",
            "453/453 [==============================] - 0s 669us/sample - loss: 0.1940 - accuracy: 0.9470\n",
            "Epoch 412/500\n",
            "453/453 [==============================] - 0s 621us/sample - loss: 0.1904 - accuracy: 0.9492\n",
            "Epoch 413/500\n",
            "453/453 [==============================] - 0s 622us/sample - loss: 0.1797 - accuracy: 0.9514\n",
            "Epoch 414/500\n",
            "453/453 [==============================] - 0s 615us/sample - loss: 0.1792 - accuracy: 0.9492\n",
            "Epoch 415/500\n",
            "453/453 [==============================] - 0s 695us/sample - loss: 0.1794 - accuracy: 0.9492\n",
            "Epoch 416/500\n",
            "453/453 [==============================] - 0s 726us/sample - loss: 0.1781 - accuracy: 0.9536\n",
            "Epoch 417/500\n",
            "453/453 [==============================] - 0s 613us/sample - loss: 0.1770 - accuracy: 0.9492\n",
            "Epoch 418/500\n",
            "453/453 [==============================] - 0s 632us/sample - loss: 0.1761 - accuracy: 0.9448\n",
            "Epoch 419/500\n",
            "453/453 [==============================] - 0s 655us/sample - loss: 0.1742 - accuracy: 0.9514\n",
            "Epoch 420/500\n",
            "453/453 [==============================] - 0s 602us/sample - loss: 0.1732 - accuracy: 0.9492\n",
            "Epoch 421/500\n",
            "453/453 [==============================] - 0s 675us/sample - loss: 0.1732 - accuracy: 0.9470\n",
            "Epoch 422/500\n",
            "453/453 [==============================] - 0s 682us/sample - loss: 0.1716 - accuracy: 0.9514\n",
            "Epoch 423/500\n",
            "453/453 [==============================] - 0s 652us/sample - loss: 0.1720 - accuracy: 0.9492\n",
            "Epoch 424/500\n",
            "453/453 [==============================] - 0s 605us/sample - loss: 0.1719 - accuracy: 0.9448\n",
            "Epoch 425/500\n",
            "453/453 [==============================] - 0s 623us/sample - loss: 0.1704 - accuracy: 0.9492\n",
            "Epoch 426/500\n",
            "453/453 [==============================] - 0s 611us/sample - loss: 0.1695 - accuracy: 0.9470\n",
            "Epoch 427/500\n",
            "453/453 [==============================] - 0s 663us/sample - loss: 0.1683 - accuracy: 0.9448\n",
            "Epoch 428/500\n",
            "453/453 [==============================] - 0s 693us/sample - loss: 0.1689 - accuracy: 0.9492\n",
            "Epoch 429/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 0.1677 - accuracy: 0.9514\n",
            "Epoch 430/500\n",
            "453/453 [==============================] - 0s 611us/sample - loss: 0.1685 - accuracy: 0.9492\n",
            "Epoch 431/500\n",
            "453/453 [==============================] - 0s 650us/sample - loss: 0.1666 - accuracy: 0.9492\n",
            "Epoch 432/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 0.1656 - accuracy: 0.9492\n",
            "Epoch 433/500\n",
            "453/453 [==============================] - 0s 612us/sample - loss: 0.1650 - accuracy: 0.9470\n",
            "Epoch 434/500\n",
            "453/453 [==============================] - 0s 672us/sample - loss: 0.1639 - accuracy: 0.9492\n",
            "Epoch 435/500\n",
            "453/453 [==============================] - 0s 677us/sample - loss: 0.1645 - accuracy: 0.9470\n",
            "Epoch 436/500\n",
            "453/453 [==============================] - 0s 671us/sample - loss: 0.1643 - accuracy: 0.9404\n",
            "Epoch 437/500\n",
            "453/453 [==============================] - 0s 621us/sample - loss: 0.1631 - accuracy: 0.9448\n",
            "Epoch 438/500\n",
            "453/453 [==============================] - 0s 619us/sample - loss: 0.1624 - accuracy: 0.9426\n",
            "Epoch 439/500\n",
            "453/453 [==============================] - 0s 640us/sample - loss: 0.1620 - accuracy: 0.9492\n",
            "Epoch 440/500\n",
            "453/453 [==============================] - 0s 603us/sample - loss: 0.1605 - accuracy: 0.9536\n",
            "Epoch 441/500\n",
            "453/453 [==============================] - 0s 662us/sample - loss: 0.1600 - accuracy: 0.9536\n",
            "Epoch 442/500\n",
            "453/453 [==============================] - 0s 674us/sample - loss: 0.1609 - accuracy: 0.9492\n",
            "Epoch 443/500\n",
            "453/453 [==============================] - 0s 651us/sample - loss: 0.1593 - accuracy: 0.9492\n",
            "Epoch 444/500\n",
            "453/453 [==============================] - 0s 658us/sample - loss: 0.1587 - accuracy: 0.9426\n",
            "Epoch 445/500\n",
            "453/453 [==============================] - 0s 608us/sample - loss: 0.1610 - accuracy: 0.9404\n",
            "Epoch 446/500\n",
            "453/453 [==============================] - 0s 631us/sample - loss: 0.1570 - accuracy: 0.9514\n",
            "Epoch 447/500\n",
            "453/453 [==============================] - 0s 601us/sample - loss: 0.1567 - accuracy: 0.9470\n",
            "Epoch 448/500\n",
            "453/453 [==============================] - 0s 644us/sample - loss: 0.1561 - accuracy: 0.9470\n",
            "Epoch 449/500\n",
            "453/453 [==============================] - 0s 667us/sample - loss: 0.1564 - accuracy: 0.9492\n",
            "Epoch 450/500\n",
            "453/453 [==============================] - 0s 657us/sample - loss: 0.1558 - accuracy: 0.9492\n",
            "Epoch 451/500\n",
            "453/453 [==============================] - 0s 724us/sample - loss: 0.1546 - accuracy: 0.9492\n",
            "Epoch 452/500\n",
            "453/453 [==============================] - 0s 652us/sample - loss: 0.1550 - accuracy: 0.9448\n",
            "Epoch 453/500\n",
            "453/453 [==============================] - 0s 620us/sample - loss: 0.1541 - accuracy: 0.9470\n",
            "Epoch 454/500\n",
            "453/453 [==============================] - 0s 598us/sample - loss: 0.1548 - accuracy: 0.9470\n",
            "Epoch 455/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 0.1548 - accuracy: 0.9470\n",
            "Epoch 456/500\n",
            "453/453 [==============================] - 0s 629us/sample - loss: 0.1560 - accuracy: 0.9492\n",
            "Epoch 457/500\n",
            "453/453 [==============================] - 0s 661us/sample - loss: 0.1519 - accuracy: 0.9492\n",
            "Epoch 458/500\n",
            "453/453 [==============================] - 0s 641us/sample - loss: 0.1516 - accuracy: 0.9470\n",
            "Epoch 459/500\n",
            "453/453 [==============================] - 0s 648us/sample - loss: 0.1502 - accuracy: 0.9448\n",
            "Epoch 460/500\n",
            "453/453 [==============================] - 0s 694us/sample - loss: 0.1503 - accuracy: 0.9514\n",
            "Epoch 461/500\n",
            "453/453 [==============================] - 0s 622us/sample - loss: 0.1494 - accuracy: 0.9536\n",
            "Epoch 462/500\n",
            "453/453 [==============================] - 0s 667us/sample - loss: 0.1494 - accuracy: 0.9492\n",
            "Epoch 463/500\n",
            "453/453 [==============================] - 0s 702us/sample - loss: 0.1486 - accuracy: 0.9448\n",
            "Epoch 464/500\n",
            "453/453 [==============================] - 0s 719us/sample - loss: 0.1475 - accuracy: 0.9470\n",
            "Epoch 465/500\n",
            "453/453 [==============================] - 0s 669us/sample - loss: 0.1472 - accuracy: 0.9492\n",
            "Epoch 466/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 0.1483 - accuracy: 0.9514\n",
            "Epoch 467/500\n",
            "453/453 [==============================] - 0s 617us/sample - loss: 0.1475 - accuracy: 0.9470\n",
            "Epoch 468/500\n",
            "453/453 [==============================] - 0s 640us/sample - loss: 0.1464 - accuracy: 0.9492\n",
            "Epoch 469/500\n",
            "453/453 [==============================] - 0s 680us/sample - loss: 0.1460 - accuracy: 0.9448\n",
            "Epoch 470/500\n",
            "453/453 [==============================] - 0s 704us/sample - loss: 0.1455 - accuracy: 0.9514\n",
            "Epoch 471/500\n",
            "453/453 [==============================] - 0s 665us/sample - loss: 0.1455 - accuracy: 0.9536\n",
            "Epoch 472/500\n",
            "453/453 [==============================] - 0s 654us/sample - loss: 0.1448 - accuracy: 0.9448\n",
            "Epoch 473/500\n",
            "453/453 [==============================] - 0s 633us/sample - loss: 0.1469 - accuracy: 0.9448\n",
            "Epoch 474/500\n",
            "453/453 [==============================] - 0s 633us/sample - loss: 0.1458 - accuracy: 0.9470\n",
            "Epoch 475/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 0.1440 - accuracy: 0.9470\n",
            "Epoch 476/500\n",
            "453/453 [==============================] - 0s 679us/sample - loss: 0.1436 - accuracy: 0.9404\n",
            "Epoch 477/500\n",
            "453/453 [==============================] - 0s 710us/sample - loss: 0.1424 - accuracy: 0.9536\n",
            "Epoch 478/500\n",
            "453/453 [==============================] - 0s 673us/sample - loss: 0.1429 - accuracy: 0.9470\n",
            "Epoch 479/500\n",
            "453/453 [==============================] - 0s 638us/sample - loss: 0.1425 - accuracy: 0.9470\n",
            "Epoch 480/500\n",
            "453/453 [==============================] - 0s 704us/sample - loss: 0.1417 - accuracy: 0.9514\n",
            "Epoch 481/500\n",
            "453/453 [==============================] - 0s 680us/sample - loss: 0.1423 - accuracy: 0.9426\n",
            "Epoch 482/500\n",
            "453/453 [==============================] - 0s 675us/sample - loss: 0.1430 - accuracy: 0.9492\n",
            "Epoch 483/500\n",
            "453/453 [==============================] - 0s 675us/sample - loss: 0.1411 - accuracy: 0.9470\n",
            "Epoch 484/500\n",
            "453/453 [==============================] - 0s 669us/sample - loss: 0.1408 - accuracy: 0.9470\n",
            "Epoch 485/500\n",
            "453/453 [==============================] - 0s 619us/sample - loss: 0.1394 - accuracy: 0.9492\n",
            "Epoch 486/500\n",
            "453/453 [==============================] - 0s 677us/sample - loss: 0.1390 - accuracy: 0.9470\n",
            "Epoch 487/500\n",
            "453/453 [==============================] - 0s 632us/sample - loss: 0.1381 - accuracy: 0.9470\n",
            "Epoch 488/500\n",
            "453/453 [==============================] - 0s 618us/sample - loss: 0.1381 - accuracy: 0.9470\n",
            "Epoch 489/500\n",
            "453/453 [==============================] - 0s 653us/sample - loss: 0.1378 - accuracy: 0.9514\n",
            "Epoch 490/500\n",
            "453/453 [==============================] - 0s 681us/sample - loss: 0.1369 - accuracy: 0.9470\n",
            "Epoch 491/500\n",
            "453/453 [==============================] - 0s 643us/sample - loss: 0.1364 - accuracy: 0.9448\n",
            "Epoch 492/500\n",
            "453/453 [==============================] - 0s 633us/sample - loss: 0.1361 - accuracy: 0.9558\n",
            "Epoch 493/500\n",
            "453/453 [==============================] - 0s 625us/sample - loss: 0.1355 - accuracy: 0.9470\n",
            "Epoch 494/500\n",
            "453/453 [==============================] - 0s 618us/sample - loss: 0.1355 - accuracy: 0.9514\n",
            "Epoch 495/500\n",
            "453/453 [==============================] - 0s 639us/sample - loss: 0.1355 - accuracy: 0.9470\n",
            "Epoch 496/500\n",
            "453/453 [==============================] - 0s 660us/sample - loss: 0.1354 - accuracy: 0.9492\n",
            "Epoch 497/500\n",
            "453/453 [==============================] - 0s 710us/sample - loss: 0.1373 - accuracy: 0.9492\n",
            "Epoch 498/500\n",
            "453/453 [==============================] - 0s 678us/sample - loss: 0.1444 - accuracy: 0.9492\n",
            "Epoch 499/500\n",
            "453/453 [==============================] - 0s 629us/sample - loss: 0.1498 - accuracy: 0.9382\n",
            "Epoch 500/500\n",
            "453/453 [==============================] - 0s 656us/sample - loss: 0.1356 - accuracy: 0.9426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHLIaJvmNbiZ",
        "colab_type": "text"
      },
      "source": [
        "## Plot the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV9v5vq_MtzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "2d404675-07aa-4be2-c43a-602c5838f954"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBYGISJRTEIiIRDkFgYhIlPv/xBNnl+ZmpwcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6mlH9ypNvPh",
        "colab_type": "text"
      },
      "source": [
        "## Generate New Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srwfDgFnNrRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fce7e115-fd0a-4abb-aceb-cbdb488cc9e0"
      },
      "source": [
        "next_words = 100\n",
        "seed_text = \"Tom Cruise went to dublin\"\n",
        "\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tom Cruise went to dublin girls and the table little milliner forget call forget call call round a call call hoops hoops hoops didnt painted call forget didnt painted forget call died for her and daughter call harp once polkas forget didnt painted forget call lads call call suppose up a call forget cask call too suppose suppose suppose academy long weeks at suppose suppose brooks hoops forget call too suppose suppose suppose academy academy academy long weeks at brooks academy academy academy academy academy long weeks at brooks academy academy academy academy academy academy weeks at brooks academy academy academy academy academy academy long\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}